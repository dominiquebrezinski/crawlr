#!/usr/bin/env ruby
require 'crawlr'

Crawlr::Processor.new(ARGV[0]).start do |crawlr|
  crawlr.crawl_page('http://www.malware.com.br/cgi/submit?action=list_xml') do |page|
    page.search('//url/uri/text()').each do |href|
      unless crawlr.stored? href
        puts "Fetching #{href}"
        page = crawlr.site_agent.head_page(href)
        if page && page.content_length < Crawlr::DOWNLOAD_BYTE_LIMIT
          crawlr.site_agent.get_page(href) do |malware_page|
            if malware_page.is_ok? && !malware_page.content_type_class?('text/')
              av_info = page.search("//url[uri[text()=\"#{href}\"]]/av_info/text()").first
              crawlr.store(malware_page, true, av_info)
            end
          end
        end
      end
    end
  end
end